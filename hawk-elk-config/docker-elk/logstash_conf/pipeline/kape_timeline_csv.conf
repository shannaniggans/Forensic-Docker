input {
    file {
        path => "/data/*_timeline.csv"
        start_position => "beginning"
        sincedb_path => "/dev/null"
        mode => "read"
    }
}
filter {
    if [message] =~ /^\s*$/ {   #Delete any blank lines and dont send to csv filter
        drop {}
        }
    mutate {                    #This is to remove characters that logstash doesnt like that might appear in subject lines
	gsub => ["message", "\[", "\ "]
	gsub => ["message", "\]", "\ "]
    gsub => ["message", "\{", "\("]
	gsub => ["message", "\}", "\)"]
    gsub => ["message", "\%computername\%", "SVR02"] #change this if needed
	}
    csv {
        id => "kapetimeline"
        separator => ","
        columns => ["Date","Source Type","host","SID","information"]
	 }
    date {
        match => ["Date", "yyyy-MM-d HH:mm:ss"] #pay particular attention to the syntax here
        timezone => "UTC" #Update to match the correct timezone       
        target => "@timestamp"
    }
}

output {
    elasticsearch {
        hosts => ["elasticsearch:9200"]
        index => "kapetimelinecsv"
    }
    stdout { codec => rubydebug }
}
